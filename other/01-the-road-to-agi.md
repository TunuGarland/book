The beginning of a new year is prediction season. After the success of neural-network algorithms during 2022, particularly ChatGPT at the end of the year, tech tweeters are extrapolating that success into 2023. A lot of people believe that 2023 will be a big year for AI.

By artificial intelligence, I mean algorithms that can be creative in some sense. Creating knowledge. Moreover, that creativity and knowledge-creation should be in the real world, not in bounded domains that humans fully understand and can explain comprehensively to the algorithm how it works, such as a game. We cannot explain fully to an algorithm how the real world works because humans don't understand the real world fully, nor model it satisfactorily. I have seen algorithms capable of taking creativity and knowledge that has already been supplied to it by humans, searching it and outputting that knowledge again. But I haven't seen an algorithm create new knowledge. What we see today are primarily novel and sophisticated search algorithms, which is a highly useful and important innovation. But it is not AI.

This may sound like nitpitting about words. But the words matter, because referring to an algorithm such as ChatGPT as intelligence suggests a certain reach. It suggests that what is in the workings right now is intelligence, albeit unpolished, which it is not. In fact, it is the exact opposite, namely polished unintelligence masquerading as intelligence.

And this is why extrapolation fails. It is highly unlikely that we have currently managed to build the embryo of intelligence. True intelligence won't be achieved simply by scaling today's algorithms with more neurons and larger training sets. Something fundamentally different is necessary. In fact, the returns of developing the current algorithms will likely diminish. If the algorithm has already seen one million pictures of cats, why would the one million and first image be the one that makes the difference?1

To get to AGI, we need something fundamentally different. We are missing the essence of what it means for an algorithm to be intelligent - for an algorithm to think. I think that this explanation might contain neurons as some small part of it,  because the only general intelligence machine that we know of - the human brain - works with something resembling neural nets as a part of it. But to get there, we need to look for something entirely different. And at the moment, very few people are doing that.
